BETA 0.0
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 16.   15.    4.5]
Final Optimal cost associated with the policy
[ 16.   15.    4.5]


 ------------ 


BETA 0.05
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 16.54406586  15.75739423   5.21856841]
Final Optimal cost associated with the policy
[ 16.54406586  15.75739423   5.21856841]


 ------------ 


BETA 0.1
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 17.15806025  16.59699455   6.0031447 ]
Final Optimal cost associated with the policy
[ 17.15806025  16.59699455   6.0031447 ]


 ------------ 


BETA 0.15
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 17.85400435  17.53295019   6.86605461]
Final Optimal cost associated with the policy
[ 17.85400443  17.53295028   6.8660547 ]


 ------------ 


BETA 0.2
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 18.64696304  18.5828718    7.82267961]
Final Optimal cost associated with the policy
[ 18.64696457  18.58287342   7.82268115]


 ------------ 


BETA 0.25
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 19.5560546   19.76895513   8.89247341]
Final Optimal cost associated with the policy
[ 19.55606981  19.76897117   8.89248867]


 ------------ 


BETA 0.3
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 20.60586771  21.11954937  10.10038777]
Final Optimal cost associated with the policy
[ 20.60596865  21.1196557   10.100489  ]


 ------------ 


BETA 0.35
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 21.82845236  22.67135012  11.47887479]
Final Optimal cost associated with the policy
[ 21.82896027  22.67188473  11.47938413]


 ------------ 


BETA 0.4
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 23.26610409  24.47245314  13.07068623]
Final Optimal cost associated with the policy
[ 23.26819598  24.47465307  13.07278391]


 ------------ 


BETA 0.45
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 24.97522187  26.58657043  14.9327511 ]
Final Optimal cost associated with the policy
[ 24.98263383  26.59435749  14.94018318]


 ------------ 


BETA 0.5
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 27.03158968  29.0987848   17.1414831 ]
Final Optimal cost associated with the policy
[ 27.05497771  29.12332838  17.16493314]


 ------------ 


BETA 0.55
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 29.53750965  32.12330203  19.79994747]
Final Optimal cost associated with the policy
[ 29.60492927  32.19395886  19.86754081]


 ------------ 


BETA 0.6
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 32.63130111  35.81375275  23.04740352]
Final Optimal cost associated with the policy
[ 32.81241492  36.00326708  23.22896815]


 ------------ 


BETA 0.65
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 36.49977485  40.3766972   27.07183462]
Final Optimal cost associated with the policy
[ 36.96079076  40.85820022  27.53395004]


 ------------ 


BETA 0.7
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 41.39439523  46.08909672  32.12618101]
Final Optimal cost associated with the policy
[ 42.52339205  47.26561034  33.25772809]


 ------------ 


BETA 0.75
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 47.65195465  53.32063537  38.54910299]
Final Optimal cost associated with the policy
[ 50.35424764  56.12881732  41.2570794 ]


 ------------ 


BETA 0.8
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 55.720705    62.56190344  46.79122297]
Final Optimal cost associated with the policy
[ 62.1656051   69.23566879  53.24840764]


 ------------ 


BETA 0.85
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 66.19301978  74.45959252  57.44792392]
Final Optimal cost associated with the policy
[ 81.96255404  90.713441    73.24345547]


 ------------ 


BETA 0.9
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[ 79.84579753  89.85999802  71.29991951]
Final Optimal cost associated with the policy
[ 121.78851002  132.8167706   113.2970678 ]


 ------------ 


BETA 0.95
Modified Policy Iteration: Starting with initial policy [0 0 0]
Final optimal policy
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Final MPI cost
[  97.68996288  109.86228099   89.36295747]
Final Optimal cost associated with the policy
[ 241.97938806  256.28102819  233.76669206]


 ------------ 


