BETA 0.0
 Value Iteration: Starting with end stage costs as [ 0.  0.  0.]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 16.   15.    4.5]


 ------------ 


BETA 0.05
 Value Iteration: Starting with end stage costs as [ 16.   15.    4.5]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 16.54406586  15.75739423   5.21856841]


 ------------ 


BETA 0.1
 Value Iteration: Starting with end stage costs as [ 16.54406586  15.75739423   5.21856841]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 17.15806025  16.59699455   6.0031447 ]


 ------------ 


BETA 0.15
 Value Iteration: Starting with end stage costs as [ 17.15806025  16.59699455   6.0031447 ]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 17.85400443  17.53295028   6.8660547 ]


 ------------ 


BETA 0.2
 Value Iteration: Starting with end stage costs as [ 17.85400443  17.53295028   6.8660547 ]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 18.64696457  18.58287342   7.82268115]


 ------------ 


BETA 0.25
 Value Iteration: Starting with end stage costs as [ 18.64696457  18.58287342   7.82268115]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 19.55606981  19.76897117   8.89248867]


 ------------ 


BETA 0.3
 Value Iteration: Starting with end stage costs as [ 19.55606981  19.76897117   8.89248867]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 20.60596865  21.1196557   10.100489  ]


 ------------ 


BETA 0.35
 Value Iteration: Starting with end stage costs as [ 20.60596865  21.1196557   10.100489  ]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 21.82896027  22.67188473  11.47938413]


 ------------ 


BETA 0.4
 Value Iteration: Starting with end stage costs as [ 21.82896027  22.67188473  11.47938413]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 23.26819598  24.47465307  13.07278391]


 ------------ 


BETA 0.45
 Value Iteration: Starting with end stage costs as [ 23.26819598  24.47465307  13.07278391]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 24.98263383  26.59435749  14.94018318]


 ------------ 


BETA 0.5
 Value Iteration: Starting with end stage costs as [ 24.98263383  26.59435749  14.94018318]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 27.05497771  29.12332838  17.16493313]


 ------------ 


BETA 0.55
 Value Iteration: Starting with end stage costs as [ 27.05497771  29.12332838  17.16493313]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 29.60492919  32.19395878  19.86754073]


 ------------ 


BETA 0.6
 Value Iteration: Starting with end stage costs as [ 29.60492919  32.19395878  19.86754073]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 32.81241368  36.00326585  23.22896691]


 ------------ 


BETA 0.65
 Value Iteration: Starting with end stage costs as [ 32.81241368  36.00326585  23.22896691]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 36.96077457  40.858184    27.53393385]


 ------------ 


BETA 0.7
 Value Iteration: Starting with end stage costs as [ 36.96077457  40.858184    27.53393385]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 42.52320685  47.26542489  33.25754287]


 ------------ 


BETA 0.75
 Value Iteration: Starting with end stage costs as [ 42.52320685  47.26542489  33.25754287]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 50.35233016  56.12689762  41.25516181]


 ------------ 


BETA 0.8
 Value Iteration: Starting with end stage costs as [ 50.35233016  56.12689762  41.25516181]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 62.14691002  69.21695539  53.22971158]


 ------------ 


BETA 0.85
 Value Iteration: Starting with end stage costs as [ 62.14691002  69.21695539  53.22971158]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 81.78164264  90.53239049  73.0625366 ]


 ------------ 


BETA 0.9
 Value Iteration: Starting with end stage costs as [ 81.78164264  90.53239049  73.0625366 ]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 119.88329957  130.91056428  111.39180388]


 ------------ 


BETA 0.95
 Value Iteration: Starting with end stage costs as [ 119.88329957  130.91056428  111.39180388]
Optimal policy is 
{'state 0': 'action 1', 'state 1': 'action 1', 'state 2': 'action 2'}
Cost is [ 214.25343941  228.54817192  206.04037252]


 ------------ 


